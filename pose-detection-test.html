<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>å§¿æ€æ£€æµ‹æµ‹è¯• - å¤šç§æ–¹æ³•</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 20px; background: #f5f5f5; }
        .container { max-width: 1200px; margin: 0 auto; background: white; padding: 20px; border-radius: 10px; }
        h1 { color: #333; text-align: center; }
        .method-section { margin: 20px 0; padding: 15px; border: 2px solid #ddd; border-radius: 8px; }
        .method-section.active { border-color: #007bff; background: #f8f9ff; }
        .controls { text-align: center; margin: 15px 0; }
        button { padding: 10px 20px; margin: 5px; border: none; border-radius: 5px; cursor: pointer; font-size: 14px; }
        .btn-primary { background: #007bff; color: white; }
        .btn-success { background: #28a745; color: white; }
        .btn-danger { background: #dc3545; color: white; }
        .btn-warning { background: #ffc107; color: #212529; }
        .video-container { text-align: center; margin: 20px 0; }
        canvas, video { border: 2px solid #333; margin: 10px; max-width: 100%; }
        .status { padding: 10px; margin: 10px 0; border-radius: 5px; text-align: center; }
        .status.success { background: #d4edda; color: #155724; border: 1px solid #c3e6cb; }
        .status.error { background: #f8d7da; color: #721c24; border: 1px solid #f5c6cb; }
        .status.info { background: #d1ecf1; color: #0c5460; border: 1px solid #bee5eb; }
        .log { background: #f8f9fa; padding: 15px; margin: 10px 0; border-radius: 5px; font-family: monospace; font-size: 12px; white-space: pre-wrap; max-height: 200px; overflow-y: auto; }
    </style>
</head>
<body>
    <div class="container">
        <h1>ğŸ¯ å§¿æ€æ£€æµ‹æµ‹è¯• - å¤šç§æ–¹æ³•å¯¹æ¯”</h1>
        
        <div class="controls">
            <button class="btn-primary" onclick="initCamera()">å¯ç”¨æ‘„åƒå¤´</button>
            <button class="btn-warning" onclick="clearConsole()">æ¸…ç©ºæ§åˆ¶å°</button>
        </div>

        <div class="video-container">
            <video id="video" width="640" height="480" autoplay muted playsinline style="display:none;"></video>
            <canvas id="canvas" width="640" height="480"></canvas>
        </div>

        <div class="status info" id="status">å‡†å¤‡å°±ç»ª - ç‚¹å‡»å¯ç”¨æ‘„åƒå¤´å¼€å§‹æµ‹è¯•</div>

        <!-- æ–¹æ³•1: ml5.js PoseNet -->
        <div class="method-section" id="method1">
            <h3>æ–¹æ³•1: ml5.js PoseNet</h3>
            <div class="controls">
                <button class="btn-success" onclick="testML5PoseNet()">æµ‹è¯• ml5.js</button>
                <button class="btn-danger" onclick="stopML5()">åœæ­¢</button>
            </div>
            <div class="log" id="log1">ç­‰å¾…æµ‹è¯•...</div>
        </div>

        <!-- æ–¹æ³•2: TensorFlow.js ç›´æ¥è°ƒç”¨ -->
        <div class="method-section" id="method2">
            <h3>æ–¹æ³•2: TensorFlow.js PoseNet</h3>
            <div class="controls">
                <button class="btn-success" onclick="testTensorFlowPoseNet()">æµ‹è¯• TensorFlow.js</button>
                <button class="btn-danger" onclick="stopTensorFlow()">åœæ­¢</button>
            </div>
            <div class="log" id="log2">ç­‰å¾…æµ‹è¯•...</div>
        </div>

        <!-- æ–¹æ³•3: MediaPipe Pose -->
        <div class="method-section" id="method3">
            <h3>æ–¹æ³•3: MediaPipe Pose</h3>
            <div class="controls">
                <button class="btn-success" onclick="testMediaPipe()">æµ‹è¯• MediaPipe</button>
                <button class="btn-danger" onclick="stopMediaPipe()">åœæ­¢</button>
            </div>
            <div class="log" id="log3">ç­‰å¾…æµ‹è¯•...</div>
        </div>
    </div>

    <!-- åŠ è½½å¿…è¦çš„åº“ -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.21.0/dist/tf.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/pose-detection@2.0.0/dist/pose-detection.min.js"></script>
    <script src="https://unpkg.com/ml5@0.12.2/dist/ml5.min.js"></script>

    <script>
        let video, canvas, ctx;
        let currentDetector = null;
        let animationId = null;

        function log(message, methodId = 'status') {
            const timestamp = new Date().toLocaleTimeString();
            const logElement = document.getElementById(methodId === 'status' ? 'status' : `log${methodId}`);
            if (logElement) {
                if (methodId === 'status') {
                    logElement.textContent = message;
                    logElement.className = 'status info';
                } else {
                    logElement.textContent += `[${timestamp}] ${message}\n`;
                    logElement.scrollTop = logElement.scrollHeight;
                }
            }
            console.log(`[${methodId}] ${message}`);
        }

        async function initCamera() {
            try {
                log('æ­£åœ¨å¯ç”¨æ‘„åƒå¤´...', 'status');

                const stream = await navigator.mediaDevices.getUserMedia({
                    video: { width: 640, height: 480, facingMode: 'user' }
                });

                video = document.getElementById('video');
                canvas = document.getElementById('canvas');
                ctx = canvas.getContext('2d');

                video.srcObject = stream;
                video.autoplay = true;
                video.muted = true;
                video.playsInline = true;

                // å¼ºåˆ¶æ’­æ”¾è§†é¢‘
                video.play().then(() => {
                    log('è§†é¢‘æ’­æ”¾æˆåŠŸ', 'status');
                }).catch(err => {
                    log('è§†é¢‘æ’­æ”¾å¤±è´¥: ' + err.message, 'status');
                });

                video.onloadedmetadata = () => {
                    log(`è§†é¢‘å…ƒæ•°æ®åŠ è½½: ${video.videoWidth}x${video.videoHeight}`, 'status');
                };

                video.onloadeddata = () => {
                    log('è§†é¢‘æ•°æ®åŠ è½½å®Œæˆ', 'status');
                };

                video.onplaying = () => {
                    log('æ‘„åƒå¤´å¯ç”¨æˆåŠŸ - å¯ä»¥å¼€å§‹æµ‹è¯•å„ç§æ–¹æ³•', 'status');
                    startVideoPreview();
                };

            } catch (error) {
                log('æ‘„åƒå¤´å¯ç”¨å¤±è´¥: ' + error.message, 'status');
                document.getElementById('status').className = 'status error';
            }
        }

        function startVideoPreview() {
            let frameCount = 0;

            function drawFrame() {
                if (video && video.readyState >= 2 && !video.paused) {
                    try {
                        ctx.clearRect(0, 0, canvas.width, canvas.height);
                        ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

                        // ç»˜åˆ¶æµ‹è¯•æ ‡è®°ç¡®è®¤ç»˜åˆ¶æ­£å¸¸
                        ctx.fillStyle = '#ff0000';
                        ctx.beginPath();
                        ctx.arc(50, 50, 10, 0, 2 * Math.PI);
                        ctx.fill();

                        frameCount++;
                        if (frameCount === 1) {
                            log('âœ… è§†é¢‘é¢„è§ˆå¼€å§‹æ­£å¸¸æ˜¾ç¤º', 'status');
                        }
                    } catch (error) {
                        log('ç»˜åˆ¶é”™è¯¯: ' + error.message, 'status');
                    }
                } else if (frameCount < 10) {
                    log(`ç­‰å¾…è§†é¢‘å‡†å¤‡: readyState=${video?.readyState}, paused=${video?.paused}`, 'status');
                }

                if (!currentDetector) {
                    requestAnimationFrame(drawFrame);
                }
            }

            // å»¶è¿Ÿå¯åŠ¨ç»˜åˆ¶ï¼Œç¡®ä¿è§†é¢‘å®Œå…¨å‡†å¤‡å¥½
            setTimeout(drawFrame, 500);
        }

        // æ–¹æ³•1: ml5.js PoseNet
        async function testML5PoseNet() {
            try {
                if (!video || video.readyState < 2) {
                    log('è¯·å…ˆå¯ç”¨æ‘„åƒå¤´', 1);
                    return;
                }

                log('åˆå§‹åŒ– ml5.js PoseNet...', 1);
                document.getElementById('method1').className = 'method-section active';

                // æ£€æŸ¥ml5ç‰ˆæœ¬å’Œå¯ç”¨æ€§
                log(`ml5ç‰ˆæœ¬: ${ml5.version || 'unknown'}`, 1);
                log(`ml5.poseNetå¯ç”¨: ${typeof ml5.poseNet !== 'undefined'}`, 1);

                if (typeof ml5.poseNet === 'undefined') {
                    log('âŒ ml5.poseNetä¸å¯ç”¨ï¼Œè¯·å°è¯•å…¶ä»–æ–¹æ³•', 1);
                    return;
                }
                
                const poseNet = await ml5.poseNet(video, {
                    architecture: 'MobileNetV1',
                    imageScaleFactor: 0.3,
                    outputStride: 16,
                    flipHorizontal: false,
                    minConfidence: 0.1,
                    maxPoseDetections: 1,
                    scoreThreshold: 0.1,
                    detectionType: 'single'
                });

                log('ml5.js PoseNet åˆå§‹åŒ–æˆåŠŸ', 1);
                currentDetector = 'ml5';

                poseNet.on('pose', (results) => {
                    if (results && results.length > 0) {
                        log(`æ£€æµ‹åˆ° ${results.length} ä¸ªå§¿æ€`, 1);
                        console.group('ğŸ¯ ml5.js PoseNet æ£€æµ‹ç»“æœ');
                        console.log('ç»“æœ:', results);
                        
                        results.forEach((result, index) => {
                            if (result.pose && result.pose.keypoints) {
                                console.log(`å§¿æ€ ${index + 1} - å…³é”®ç‚¹æ•°é‡:`, result.pose.keypoints.length);
                                console.table(result.pose.keypoints.map(kp => ({
                                    éƒ¨ä½: kp.part,
                                    X: Math.round(kp.position.x),
                                    Y: Math.round(kp.position.y),
                                    ç½®ä¿¡åº¦: Math.round(kp.score * 100) / 100
                                })));
                            }
                        });
                        console.groupEnd();
                        
                        // ç»˜åˆ¶å…³é”®ç‚¹
                        drawKeypoints(results[0].pose.keypoints, '#ff0000');
                    }
                });

            } catch (error) {
                log('ml5.js æµ‹è¯•å¤±è´¥: ' + error.message, 1);
                console.error('ml5.js é”™è¯¯:', error);
            }
        }

        function stopML5() {
            currentDetector = null;
            document.getElementById('method1').className = 'method-section';
            log('ml5.js æ£€æµ‹å·²åœæ­¢', 1);
            startVideoPreview();
        }

        function drawKeypoints(keypoints, color = '#ff0000') {
            ctx.fillStyle = color;
            keypoints.forEach(keypoint => {
                if (keypoint.score > 0.1) {
                    ctx.beginPath();
                    ctx.arc(keypoint.position.x, keypoint.position.y, 5, 0, 2 * Math.PI);
                    ctx.fill();
                }
            });
        }

        function clearConsole() {
            console.clear();
            log('æ§åˆ¶å°å·²æ¸…ç©º', 'status');
        }

        // æ–¹æ³•2: TensorFlow.js PoseNet ç›´æ¥è°ƒç”¨
        async function testTensorFlowPoseNet() {
            try {
                if (!video || video.readyState < 2) {
                    log('è¯·å…ˆå¯ç”¨æ‘„åƒå¤´', 2);
                    return;
                }

                log('åˆå§‹åŒ– TensorFlow.js PoseNet...', 2);
                document.getElementById('method2').className = 'method-section active';

                // åŠ è½½PoseNetæ¨¡å‹
                const net = await poseDetection.createDetector(
                    poseDetection.SupportedModels.PoseNet,
                    {
                        architecture: 'MobileNetV1',
                        outputStride: 16,
                        inputResolution: { width: 640, height: 480 },
                        multiplier: 0.75,
                        quantBytes: 2
                    }
                );

                log('TensorFlow.js PoseNet æ¨¡å‹åŠ è½½æˆåŠŸ', 2);
                currentDetector = 'tensorflow';

                async function detectPoses() {
                    if (currentDetector !== 'tensorflow') return;

                    try {
                        const poses = await net.estimatePoses(video);

                        if (poses && poses.length > 0) {
                            log(`æ£€æµ‹åˆ° ${poses.length} ä¸ªå§¿æ€`, 2);

                            console.group('ğŸ¯ TensorFlow.js PoseNet æ£€æµ‹ç»“æœ');
                            console.log('ç»“æœ:', poses);

                            poses.forEach((pose, index) => {
                                if (pose.keypoints) {
                                    console.log(`å§¿æ€ ${index + 1} - å…³é”®ç‚¹æ•°é‡:`, pose.keypoints.length);
                                    console.log(`å§¿æ€ç½®ä¿¡åº¦:`, pose.score);
                                    console.table(pose.keypoints.map(kp => ({
                                        éƒ¨ä½: kp.name,
                                        X: Math.round(kp.x),
                                        Y: Math.round(kp.y),
                                        ç½®ä¿¡åº¦: Math.round(kp.score * 100) / 100
                                    })));
                                }
                            });
                            console.groupEnd();

                            // ç»˜åˆ¶å…³é”®ç‚¹
                            if (video && video.readyState >= 2) {
                                ctx.clearRect(0, 0, canvas.width, canvas.height);
                                ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
                                drawTensorFlowKeypoints(poses[0].keypoints, '#00ff00');
                            }
                        }

                        requestAnimationFrame(detectPoses);

                    } catch (error) {
                        log('æ£€æµ‹è¿‡ç¨‹å‡ºé”™: ' + error.message, 2);
                        console.error('TensorFlow.js æ£€æµ‹é”™è¯¯:', error);
                    }
                }

                detectPoses();

            } catch (error) {
                log('TensorFlow.js æµ‹è¯•å¤±è´¥: ' + error.message, 2);
                console.error('TensorFlow.js é”™è¯¯:', error);
            }
        }

        function stopTensorFlow() {
            currentDetector = null;
            document.getElementById('method2').className = 'method-section';
            log('TensorFlow.js æ£€æµ‹å·²åœæ­¢', 2);
            startVideoPreview();
        }

        function drawTensorFlowKeypoints(keypoints, color = '#00ff00') {
            ctx.fillStyle = color;
            keypoints.forEach(keypoint => {
                if (keypoint.score > 0.1) {
                    ctx.beginPath();
                    ctx.arc(keypoint.x, keypoint.y, 5, 0, 2 * Math.PI);
                    ctx.fill();
                }
            });
        }

        // æ–¹æ³•3: MediaPipe Pose
        async function testMediaPipe() {
            try {
                if (!video || video.readyState < 2) {
                    log('è¯·å…ˆå¯ç”¨æ‘„åƒå¤´', 3);
                    return;
                }

                log('åˆå§‹åŒ– MediaPipe Pose...', 3);
                document.getElementById('method3').className = 'method-section active';

                // ä½¿ç”¨TensorFlow.jsçš„MediaPipeæ¨¡å‹
                const detector = await poseDetection.createDetector(
                    poseDetection.SupportedModels.BlazePose,
                    {
                        runtime: 'tfjs',
                        modelType: 'lite',
                        enableSmoothing: true,
                        enableSegmentation: false
                    }
                );

                log('MediaPipe Pose æ¨¡å‹åŠ è½½æˆåŠŸ', 3);
                currentDetector = 'mediapipe';

                async function detectPoses() {
                    if (currentDetector !== 'mediapipe') return;

                    try {
                        const poses = await detector.estimatePoses(video);

                        if (poses && poses.length > 0) {
                            log(`æ£€æµ‹åˆ° ${poses.length} ä¸ªå§¿æ€`, 3);

                            console.group('ğŸ¯ MediaPipe Pose æ£€æµ‹ç»“æœ');
                            console.log('ç»“æœ:', poses);

                            poses.forEach((pose, index) => {
                                if (pose.keypoints) {
                                    console.log(`å§¿æ€ ${index + 1} - å…³é”®ç‚¹æ•°é‡:`, pose.keypoints.length);
                                    console.log(`å§¿æ€ç½®ä¿¡åº¦:`, pose.score);
                                    console.table(pose.keypoints.map(kp => ({
                                        éƒ¨ä½: kp.name,
                                        X: Math.round(kp.x),
                                        Y: Math.round(kp.y),
                                        ç½®ä¿¡åº¦: Math.round(kp.score * 100) / 100
                                    })));
                                }
                            });
                            console.groupEnd();

                            // ç»˜åˆ¶å…³é”®ç‚¹
                            if (video && video.readyState >= 2) {
                                ctx.clearRect(0, 0, canvas.width, canvas.height);
                                ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
                                drawMediaPipeKeypoints(poses[0].keypoints, '#0000ff');
                            }
                        }

                        requestAnimationFrame(detectPoses);

                    } catch (error) {
                        log('æ£€æµ‹è¿‡ç¨‹å‡ºé”™: ' + error.message, 3);
                        console.error('MediaPipe æ£€æµ‹é”™è¯¯:', error);
                    }
                }

                detectPoses();

            } catch (error) {
                log('MediaPipe æµ‹è¯•å¤±è´¥: ' + error.message, 3);
                console.error('MediaPipe é”™è¯¯:', error);
            }
        }

        function stopMediaPipe() {
            currentDetector = null;
            document.getElementById('method3').className = 'method-section';
            log('MediaPipe æ£€æµ‹å·²åœæ­¢', 3);
            startVideoPreview();
        }

        function drawMediaPipeKeypoints(keypoints, color = '#0000ff') {
            ctx.fillStyle = color;
            keypoints.forEach(keypoint => {
                if (keypoint.score > 0.1) {
                    ctx.beginPath();
                    ctx.arc(keypoint.x, keypoint.y, 5, 0, 2 * Math.PI);
                    ctx.fill();
                }
            });
        }
    </script>
</body>
</html>
